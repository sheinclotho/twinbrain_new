"""
TwinBrain V5 ä¸»ç¨‹åº
==================

å›¾åŸç”Ÿæ•°å­—å­ªç”Ÿè„‘è®­ç»ƒç³»ç»Ÿ

ä½¿ç”¨æ–¹æ³•:
    python main.py --config configs/default.yaml
    
æˆ–ç›´æ¥è¿è¡Œ:
    python main.py  # ä½¿ç”¨é»˜è®¤é…ç½®
"""

import argparse
import logging
import sys
from pathlib import Path
import yaml
import torch
import numpy as np
from torch_geometric.data import HeteroData

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from data.loaders import BrainDataLoader
from models.graph_native_mapper import GraphNativeBrainMapper
from models.graph_native_system import GraphNativeBrainModel, GraphNativeTrainer
from utils.helpers import setup_logging, set_seed, save_config, create_output_dir


def load_config(config_path: str = None) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if config_path is None:
        config_path = Path(__file__).parent / "configs" / "default.yaml"
    
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    return config


def prepare_data(config: dict, logger: logging.Logger):
    """å‡†å¤‡è®­ç»ƒæ•°æ®"""
    logger.info("=" * 60)
    logger.info("æ­¥éª¤ 1/4: åŠ è½½æ•°æ®")
    logger.info("=" * 60)
    
    # åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
    data_loader = BrainDataLoader(
        data_root=config['data']['root_dir'],
        modalities=config['data']['modalities'],
    )
    
    # åŠ è½½æ‰€æœ‰è¢«è¯•
    all_data = data_loader.load_all_subjects(
        task=config['data'].get('task'),
        max_subjects=config['data'].get('max_subjects'),
    )
    
    if not all_data:
        raise ValueError("æœªåŠ è½½åˆ°ä»»ä½•æ•°æ®ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„é…ç½®")
    
    logger.info(f"æˆåŠŸåŠ è½½ {len(all_data)} ä¸ªè¢«è¯•æ•°æ®")
    
    return all_data


def build_graphs(all_data, config: dict, logger: logging.Logger):
    """æ„å»ºå›¾ç»“æ„"""
    logger.info("=" * 60)
    logger.info("æ­¥éª¤ 2/4: æ„å»ºå›¾ç»“æ„")
    logger.info("=" * 60)
    
    def process_fmri_timeseries(fmri_data, min_volumes=10):
        """Helper to extract and normalize fMRI timeseries."""
        if fmri_data.ndim == 4:  # 4D fMRI
            n_volumes = fmri_data.shape[-1]
        elif fmri_data.ndim == 3:  # 3D (already ROI timeseries)
            n_volumes = fmri_data.shape[-1]
        else:
            return None, f"Unsupported fMRI shape: {fmri_data.shape}"
        
        if n_volumes < min_volumes:
            return None, f"Too few volumes: {n_volumes} < {min_volumes}"
        
        # Average and normalize
        fmri_ts = fmri_data.reshape(-1, n_volumes).mean(axis=0)
        fmri_ts = (fmri_ts - fmri_ts.mean()) / (fmri_ts.std() + 1e-8)
        return fmri_ts.reshape(1, -1), None
    
    # åˆå§‹åŒ–å›¾æ˜ å°„å™¨
    mapper = GraphNativeBrainMapper(
        atlas_name=config['data']['atlas']['name'],
        add_self_loops=config['graph']['add_self_loops'],
        make_undirected=config['graph']['make_undirected'],
        k_nearest_fmri=config['graph'].get('k_nearest_fmri', 20),
        k_nearest_eeg=config['graph'].get('k_nearest_eeg', 10),
        threshold_fmri=config['graph'].get('threshold_fmri', 0.3),
        threshold_eeg=config['graph'].get('threshold_eeg', 0.2),
        device=config['device']['type'],
    )
    
    # ä¸ºæ¯ä¸ªè¢«è¯•æ„å»ºå›¾
    graphs = []
    for subject_data in all_data:
        graph_list = []
        
        # fMRIå›¾
        if 'fmri' in subject_data:
            fmri_data = subject_data['fmri']['data']
            fmri_ts, error = process_fmri_timeseries(fmri_data)
            
            if error:
                logger.warning(f"fMRI processing failed: {error}, skipping")
                continue
            
            fmri_graph = mapper.map_fmri_to_graph(
                timeseries=fmri_ts,
                connectivity_matrix=None,  # è‡ªåŠ¨è®¡ç®—
            )
            graph_list.append(('fmri', fmri_graph))
        
        # EEGå›¾
        if 'eeg' in subject_data:
            eeg_data = subject_data['eeg']['data']  # [n_channels, n_times]
            eeg_ch_names = subject_data['eeg']['ch_names']
            
            # Validate EEG data
            if eeg_data.shape[0] < 8:
                logger.warning(f"EEG has too few channels: {eeg_data.shape[0]}, skipping")
                continue
            if eeg_data.shape[1] < 100:
                logger.warning(f"EEG has too few timepoints: {eeg_data.shape[1]}, skipping")
                continue
            if np.isnan(eeg_data).any() or np.isinf(eeg_data).any():
                logger.warning("EEG contains NaN or Inf values, skipping")
                continue
            
            eeg_graph = mapper.map_eeg_to_graph(
                timeseries=eeg_data,
                channel_names=eeg_ch_names,
            )
            graph_list.append(('eeg', eeg_graph))
        
        # åˆå¹¶å›¾ - FIX: Properly merge multi-modal graphs
        if len(graph_list) > 0:
            if len(graph_list) == 1:
                # Single modality: use as-is
                graphs.append(graph_list[0][1])
            else:
                # Multi-modal: merge into heterograph
                merged_graph = HeteroData()
                for modality, graph in graph_list:
                    # Copy node features and structure
                    for key in graph.node_types:
                        merged_graph[key].x = graph[key].x
                        if hasattr(graph[key], 'num_nodes'):
                            merged_graph[key].num_nodes = graph[key].num_nodes
                        if hasattr(graph[key], 'pos'):
                            merged_graph[key].pos = graph[key].pos
                    
                    # Copy edge structure
                    for edge_type in graph.edge_types:
                        merged_graph[edge_type].edge_index = graph[edge_type].edge_index
                        if hasattr(graph[edge_type], 'edge_attr'):
                            merged_graph[edge_type].edge_attr = graph[edge_type].edge_attr
                
                # Add cross-modal edges if we have both modalities
                if 'fmri' in merged_graph.node_types and 'eeg' in merged_graph.node_types:
                    # Create simple cross-modal connections (can be improved with atlas mapping)
                    # Returns edges from EEG to fMRI [eeg_idx, fmri_idx]
                    cross_edges = mapper.create_simple_cross_modal_edges(merged_graph)
                    if cross_edges is not None:
                        # Edge direction: EEG -> fMRI
                        merged_graph['eeg', 'projects_to', 'fmri'].edge_index = cross_edges
                
                graphs.append(merged_graph)
    
    if len(graphs) == 0:
        raise ValueError("No valid graphs constructed. Check data quality and preprocessing.")
    
    logger.info(f"æˆåŠŸæ„å»º {len(graphs)} ä¸ªå›¾")
    
    return graphs, mapper


def create_model(config: dict, logger: logging.Logger):
    """åˆ›å»ºæ¨¡å‹"""
    logger.info("=" * 60)
    logger.info("æ­¥éª¤ 3/4: åˆ›å»ºæ¨¡å‹")
    logger.info("=" * 60)
    
    # ç¡®å®šèŠ‚ç‚¹å’Œè¾¹ç±»å‹
    node_types = config['data']['modalities']
    edge_types = []
    
    for modality in node_types:
        edge_types.append((modality, 'connects', modality))
    
    # è·¨æ¨¡æ€è¾¹
    if len(node_types) > 1:
        edge_types.append((node_types[0], 'projects_to', node_types[1]))
    
    # è¾“å…¥é€šé“
    in_channels_dict = {modality: 1 for modality in node_types}
    
    # åˆ›å»ºæ¨¡å‹
    model = GraphNativeBrainModel(
        node_types=node_types,
        edge_types=edge_types,
        in_channels_dict=in_channels_dict,
        hidden_channels=config['model']['hidden_channels'],
        num_encoder_layers=config['model']['num_encoder_layers'],
        num_decoder_layers=config['model']['num_decoder_layers'],
        use_prediction=config['model']['use_prediction'],
        prediction_steps=config['model']['prediction_steps'],
        dropout=config['model']['dropout'],
        loss_type=config['model'].get('loss_type', 'mse'),
        use_gradient_checkpointing=config['training'].get('use_gradient_checkpointing', False),
    )
    
    logger.info(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    
    return model


def train_model(model, graphs, config: dict, logger: logging.Logger):
    """è®­ç»ƒæ¨¡å‹"""
    logger.info("=" * 60)
    logger.info("æ­¥éª¤ 4/4: è®­ç»ƒæ¨¡å‹")
    logger.info("=" * 60)
    
    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›† - Ensure both train and validation have samples
    if len(graphs) < 2:
        logger.error(f"âŒ æ•°æ®ä¸è¶³: éœ€è¦è‡³å°‘2ä¸ªæ ·æœ¬è¿›è¡Œè®­ç»ƒï¼Œä½†åªæœ‰ {len(graphs)} ä¸ªæ ·æœ¬")
        logger.error("æç¤º: è¯·å¢åŠ æ•°æ®é‡æˆ–è°ƒæ•´ max_subjects é…ç½®")
        raise ValueError(f"éœ€è¦è‡³å°‘2ä¸ªæ ·æœ¬è¿›è¡Œè®­ç»ƒ,ä½†åªæœ‰ {len(graphs)} ä¸ªã€‚è¯·æ£€æŸ¥æ•°æ®é…ç½®ã€‚")
    
    # Use at least 10% or 1 sample for validation, ensure both train and val have at least 1
    min_val_samples = max(1, len(graphs) // 10)
    n_train = len(graphs) - min_val_samples
    
    # Safety check: ensure both sets have at least 1 sample
    if n_train < 1:
        n_train = 1
        min_val_samples = len(graphs) - 1
    
    train_graphs = graphs[:n_train]
    val_graphs = graphs[n_train:]
    
    logger.info(f"è®­ç»ƒé›†: {len(train_graphs)} ä¸ªæ ·æœ¬")
    logger.info(f"éªŒè¯é›†: {len(val_graphs)} ä¸ªæ ·æœ¬")
    
    if len(train_graphs) < 5:
        logger.warning("âš ï¸ è®­ç»ƒæ ·æœ¬è¾ƒå°‘ï¼Œæ¨¡å‹å¯èƒ½è¿‡æ‹Ÿåˆã€‚å»ºè®®ä½¿ç”¨æ›´å¤šæ•°æ®ã€‚")
    
    # åˆ›å»ºè®­ç»ƒå™¨
    logger.info("æ­£åœ¨åˆå§‹åŒ–è®­ç»ƒå™¨...")
    if config['device'].get('use_torch_compile', True):
        logger.info("âš™ï¸ torch.compile() å·²å¯ç”¨ï¼Œé¦–æ¬¡è®­ç»ƒå¯èƒ½éœ€è¦é¢å¤–æ—¶é—´è¿›è¡Œæ¨¡å‹ç¼–è¯‘...")
    
    trainer = GraphNativeTrainer(
        model=model,
        node_types=config['data']['modalities'],
        learning_rate=config['training']['learning_rate'],
        weight_decay=config['training']['weight_decay'],
        use_adaptive_loss=config['training']['use_adaptive_loss'],
        use_eeg_enhancement=config['training']['use_eeg_enhancement'],
        use_amp=config['device'].get('use_amp', True),
        use_gradient_checkpointing=config['training'].get('use_gradient_checkpointing', False),
        use_scheduler=config['training'].get('use_scheduler', True),
        scheduler_type=config['training'].get('scheduler_type', 'cosine'),
        use_torch_compile=config['device'].get('use_torch_compile', True),
        compile_mode=config['device'].get('compile_mode', 'reduce-overhead'),
        device=config['device']['type'],
    )
    logger.info("âœ… è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
    logger.info("=" * 60)
    logger.info("å¼€å§‹è®­ç»ƒå¾ªç¯")
    logger.info("=" * 60)
    
    # è®­ç»ƒå¾ªç¯
    import time
    best_val_loss = float('inf')
    patience_counter = 0
    no_improvement_warning_shown = False
    epoch_times = []
    
    for epoch in range(1, config['training']['num_epochs'] + 1):
        epoch_start_time = time.time()
        
        # è®­ç»ƒ
        train_loss = trainer.train_epoch(train_graphs, epoch=epoch, total_epochs=config['training']['num_epochs'])
        
        epoch_time = time.time() - epoch_start_time
        epoch_times.append(epoch_time)
        
        # Estimate remaining time (after first few epochs)
        if len(epoch_times) >= 3:
            avg_epoch_time = sum(epoch_times[-5:]) / len(epoch_times[-5:])  # Use last 5 epochs
            remaining_epochs = config['training']['num_epochs'] - epoch
            eta_seconds = avg_epoch_time * remaining_epochs
            eta_minutes = eta_seconds / 60
            if eta_minutes < 60:
                eta_str = f"{eta_minutes:.1f} åˆ†é’Ÿ"
            else:
                eta_str = f"{eta_minutes/60:.1f} å°æ—¶"
        else:
            eta_str = "è®¡ç®—ä¸­..."
        
        # Memory monitoring every 10 epochs
        if epoch % 10 == 0 and torch.cuda.is_available():
            allocated_gb = torch.cuda.memory_allocated() / 1e9
            reserved_gb = torch.cuda.memory_reserved() / 1e9
            logger.info(f"  ğŸ’¾ GPU Memory: allocated={allocated_gb:.2f} GB, reserved={reserved_gb:.2f} GB")
        
        # Check for NaN loss
        if np.isnan(train_loss) or np.isinf(train_loss):
            logger.error(f"âŒ Training loss is NaN/Inf at epoch {epoch}. Stopping training.")
            raise ValueError("Training diverged: loss is NaN or Inf")
        
        # éªŒè¯
        if epoch % config['training']['val_frequency'] == 0:
            val_loss = trainer.validate(val_graphs)
            
            # Step scheduler based on validation loss (for ReduceLROnPlateau)
            trainer.step_scheduler_on_validation(val_loss)
            
            # Check for NaN validation loss
            if np.isnan(val_loss) or np.isinf(val_loss):
                logger.error(f"âŒ Validation loss is NaN/Inf at epoch {epoch}. Stopping training.")
                raise ValueError("Validation diverged: loss is NaN or Inf")
            
            logger.info(
                f"âœ“ Epoch {epoch}/{config['training']['num_epochs']}: "
                f"train_loss={train_loss:.4f}, val_loss={val_loss:.4f}, "
                f"time={epoch_time:.1f}s, ETA={eta_str}"
            )
            
            # Warn if no improvement after many epochs
            if epoch >= 50 and best_val_loss == float('inf') and not no_improvement_warning_shown:
                logger.warning("âš ï¸ No improvement in validation loss after 50 epochs. Check data quality and hyperparameters.")
                no_improvement_warning_shown = True
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_loss < best_val_loss:
                improvement = (best_val_loss - val_loss) / best_val_loss * 100 if best_val_loss != float('inf') else 100
                best_val_loss = val_loss
                patience_counter = 0
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                output_dir = Path(config['output']['output_dir'])
                checkpoint_path = output_dir / "best_model.pt"
                trainer.save_checkpoint(checkpoint_path, epoch)
                if improvement != 100:
                    logger.info(f"  ğŸ¯ ä¿å­˜æœ€ä½³æ¨¡å‹: val_loss={val_loss:.4f} (æå‡ {improvement:.1f}%)")
                else:
                    logger.info(f"  ğŸ¯ ä¿å­˜æœ€ä½³æ¨¡å‹: val_loss={val_loss:.4f}")
            else:
                patience_counter += 1
            
            # æ—©åœ
            if patience_counter >= config['training']['early_stopping_patience']:
                logger.info(f"â¹ï¸ æ—©åœè§¦å‘: {patience_counter} ä¸ªepochæ— æ”¹è¿›")
                break
        else:
            logger.info(
                f"âœ“ Epoch {epoch}/{config['training']['num_epochs']}: "
                f"train_loss={train_loss:.4f}, time={epoch_time:.1f}s, ETA={eta_str}"
            )
        
        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        if epoch % config['training']['save_frequency'] == 0:
            output_dir = Path(config['output']['output_dir'])
            checkpoint_path = output_dir / f"checkpoint_epoch_{epoch}.pt"
            trainer.save_checkpoint(checkpoint_path, epoch)
    
    logger.info("è®­ç»ƒå®Œæˆ!")
    logger.info(f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}")


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‚æ•°
    parser = argparse.ArgumentParser(description='TwinBrain V5 è®­ç»ƒç³»ç»Ÿ')
    parser.add_argument(
        '--config',
        type=str,
        default=None,
        help='é…ç½®æ–‡ä»¶è·¯å¾„ (default: configs/default.yaml)'
    )
    parser.add_argument(
        '--seed',
        type=int,
        default=42,
        help='éšæœºç§å­ (default: 42)'
    )
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = create_output_dir(
        config['output']['output_dir'],
        config['output']['experiment_name']
    )
    config['output']['output_dir'] = str(output_dir)
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(
        output_dir / "training.log",
        level=config['output']['log_level']
    )
    
    # è®¾ç½®éšæœºç§å­
    set_seed(args.seed)
    
    # ä¿å­˜é…ç½®
    save_config(config, output_dir / "config.yaml")
    
    # æ‰“å°é…ç½®
    logger.info("=" * 60)
    logger.info("TwinBrain V5 - å›¾åŸç”Ÿæ•°å­—å­ªç”Ÿè„‘è®­ç»ƒç³»ç»Ÿ")
    logger.info("=" * 60)
    logger.info(f"é…ç½®æ–‡ä»¶: {args.config or 'configs/default.yaml'}")
    logger.info(f"è¾“å‡ºç›®å½•: {output_dir}")
    logger.info(f"è®¾å¤‡: {config['device']['type']}")
    logger.info(f"éšæœºç§å­: {args.seed}")
    logger.info("=" * 60)
    
    try:
        # æ­¥éª¤1: å‡†å¤‡æ•°æ®
        all_data = prepare_data(config, logger)
        
        # æ­¥éª¤2: æ„å»ºå›¾
        graphs, mapper = build_graphs(all_data, config, logger)
        
        # æ­¥éª¤3: åˆ›å»ºæ¨¡å‹
        model = create_model(config, logger)
        
        # æ­¥éª¤4: è®­ç»ƒ
        train_model(model, graphs, config, logger)
        
        logger.info("=" * 60)
        logger.info("âœ… æ‰€æœ‰ä»»åŠ¡å®Œæˆ!")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ è¿è¡Œå¤±è´¥: {e}", exc_info=True)
        raise


if __name__ == '__main__':
    main()
