# TwinBrain V5 配置文件
# ===================
# 所有超参数均附有科学依据注释。
# 「建议」代表在典型神经影像场景下经验验证的起始值，可根据设备内存/数据量微调。

# ──────────────────────────────────────────────────────────────────────────
# 一、数据配置
# ──────────────────────────────────────────────────────────────────────────
data:
  # 数据根目录 - 修改为你的数据路径
  root_dir: "F:/twinbrain_v3/test_file3"
  
  # 要处理的模态
  modalities: ["eeg", "fmri"]
  
  # 任务名称列表 (null = 自动发现每个被试下所有任务; [] = 不过滤; ["rest","wm"] = 指定任务)
  # 每个 (被试, 任务) 组合生成一个图样本，多任务可显著增加训练数据量。
  tasks: null

  # task: (已弃用，请改用 tasks) 单任务名称；若 tasks 未设置则作为回退。
  task: null

  # EEG 任务 → fMRI 任务 显式映射（1:N 对齐场景）
  # ─────────────────────────────────────────────────────────────────────────
  # 适用场景：同一 fMRI 扫描对应多个 EEG 条件（典型例子见下方）。
  #
  # ★ ON/OFF 实验范式自动检测（无需配置此项）：
  #   若 EEG 任务名以 "ON" 或 "OFF" 结尾（如 CBON、CBOFF、ECON、ECOFF），
  #   系统会先尝试直接匹配同名 fMRI，若未找到则自动剥离后缀重试：
  #     CBON → CB, CBOFF → CB, ECON → EC, ECOFF → EC
  #     GRADON → GRAD, GRADOFF → GRAD, EOON → EO, EOOFF → EO
  #   无需任何配置，直接将此项保持 null 即可。
  #
  # 仅在以下情况才需要显式配置此项：
  #   • ON/OFF 后缀的基础名与 fMRI 任务名不一致（自动剥离的结果不正确）
  #   • 使用其他命名约定（如 GRADON→GRAD_run-2 这类非自动可推断的映射）
  #
  # 配置后的行为变化：
  #   1. 加载 fMRI 时优先按映射后的任务名查找，而非 EEG 任务名（显式 > 自动检测 > 回退）。
  #   2. 自动任务发现（tasks: null）仅扫描 EEG 文件，避免 fMRI-only 任务
  #      被当作独立 run 加载（无 EEG 配对则产生无跨模态边的单模态图）。
  #
  # 示例（手动覆盖自动检测结果，强制 CBON/CBOFF → CB）：
  #   fmri_task_mapping:
  #     CBON: CB
  #     CBOFF: CB
  #     ECON: EC
  #     ECOFF: EC
  #
  # 1:1 标准场景（EEG 任务名 == fMRI 任务名，如 rest_eeg + rest_bold）：保持 null 即可。
  fmri_task_mapping: null

  # fMRI 条件时间段截取（防止跨条件边界时序学习）
  # ─────────────────────────────────────────────────────────────────────────
  # 适用场景：多个 EEG 条件（如 GRADON/GRADOFF）共享同一 fMRI 运行（如 task-CB），
  # fMRI 文件按条件顺序包含完整会话的时序数据：
  #   t=0..T₁ TRs → 条件 1（如 GRADON）
  #   t=T₁..T₂ TRs → 条件 2（如 GRADOFF）
  #
  # ★ 为什么需要此配置（重要！）：
  #   若不截取，会产生两类时序污染错误：
  #   1. 非窗口模式（max_seq_len=300）：两个条件都从 t=0 开始截断，
  #      GRADOFF 错误地使用 GRADON 时段的 fMRI 数据，学习错误的连接结构。
  #   2. 窗口模式：滑动窗口会跨越条件边界（如 t=275-325 包含 GRADON 末尾
  #      和 GRADOFF 开头），预测损失被迫"预测"实验条件切换而非神经动态，
  #      导致模型学到虚假的时序规律（如 t=300 后 BOLD 信号突变）。
  #
  # 配置格式（单位：TR，含左不含右）：
  #   fmri_condition_bounds:
  #     <EEG任务名>: [起始TR, 终止TR]
  #
  # 示例（GRADON/GRADOFF 各对应 CB fMRI 前后 150 TRs，TR=2s）：
  #   fmri_condition_bounds:
  #     GRADON: [0, 150]     # TR 索引 0-149（会话开始后 0-300s）→ GRADON 条件
  #     GRADOFF: [150, 300]  # TR 索引 150-299（会话开始后 300-600s）→ GRADOFF 条件
  #   注：索引均为从 0 开始的累计 TR 编号（含左不含右），与 Python 切片语义一致。
  #
  # 如何确定 TR 边界：
  #   1. 查阅实验设计文档（最准确）
  #   2. 查看 BIDS events.tsv 文件中的 onset/duration
  #   3. 经验估算：total_TRs = fMRI_TR_count（可用 `fslhd bold.nii` 查看），
  #      若两个条件等时长，boundary = total_TRs / 2
  #
  # null（默认）：不截取，使用完整 fMRI 时间序列。
  #   1:1 标准场景（每个 EEG 任务有独立对应的 fMRI 文件）请保持 null。
  #   ON/OFF 共享 fMRI 场景**强烈建议**配置此项，否则存在时序污染风险。
  fmri_condition_bounds: null

  # 最大被试数 (用于测试, 0 或 null 表示处理所有)
  max_subjects: 0

  # Atlas配置（fMRI 空间分区）
  # Schaefer200: 200 ROI，性价比最高；400 ROI 精度更高但内存翻倍
  atlas:
    name: "schaefer200"
    file: "atlases/Schaefer2018_200Parcels_7Networks_order_FSLMNI152_1mm.nii"
    label_file: "atlases/schaefer200_mask_ready.json"

  # DTI 结构连通性边（可选）
  # ─────────────────────────────────────────────────────────────────────────
  # 设为 true 时，若被试目录下存在预计算的 DTI 连通性矩阵文件，则在 fMRI 节点上
  # 额外建立一套结构连通性边 ('fmri','structural','fmri')，使编码器同时利用：
  #   • ('fmri','connects','fmri')   — fMRI 时序相关（功能连通性）
  #   • ('fmri','structural','fmri') — DTI 白质纤维束（结构连通性）
  #
  # 支持的矩阵文件命名（BIDS兼容，放在被试任意子目录下）：
  #   sub-XX_*connmat*.npy  /  sub-XX_*connmat*.csv  /  sub-XX_*connmat*.tsv
  #   sub-XX_*connectivity*.npy / .csv
  #
  # DTI 预处理需要外部工具，本系统只读取其输出矩阵（[N_rois, N_rois]）。
  # 矩阵尺寸必须与 fMRI 图谱 ROI 数量完全一致（如 Schaefer200 → 200×200）。
  #
  # 如何生成（推荐流程）：
  #   ① 纤维跟踪（MRtrix3 示例）：
  #      tckgen dwi.mif tracks.tck -algorithm iFOD2 -select 1M
  #      tcksift2 tracks.tck fod.mif weights.txt  # SIFT2 权重归一化（推荐）
  #   ② 图谱分区（MRtrix3，与 fMRI 使用同一 atlas）：
  #      tck2connectome tracks.tck Schaefer200.nii connmat.csv \
  #          -tck_weights_in weights.txt -stat_edge mean
  #   ③ 保存（Python）：
  #      import numpy as np
  #      mat = np.log1p(np.loadtxt('connmat.csv', delimiter=','))  # log1p 归一化
  #      np.save('sub-01_connmat.npy', mat.astype('float32'))
  #
  #   Dipy 替代方案（参见 dipy.tracking.utils.connectivity_matrix）：
  #      from dipy.tracking.utils import connectivity_matrix
  #      M, grouping = connectivity_matrix(streamlines, affine, label_volume,
  #                                        return_mapping=True)
  #      np.save('sub-01_connmat.npy', M.astype('float32'))
  #
  # false（默认）：不使用 DTI，与旧版本行为一致。
  dti_structural_edges: false

  # 图缓存配置
  # 每个 (被试, 任务) 的异质图构建完成后自动保存为 .pt 文件。
  # 再次运行时直接加载，无需重新预处理，节省数分钟到数十分钟。
  # 缓存文件名包含配置哈希，修改图参数后自动失效并重建。
  cache:
    enabled: true
    dir: "outputs/graph_cache"

# ──────────────────────────────────────────────────────────────────────────
# 二、模型结构
# ──────────────────────────────────────────────────────────────────────────
model:
  # 模型类型
  type: "v5_optimized"
  
  # 隐层特征维度（H）
  # 建议：
  #   8 GB GPU  → 64（安全）或 128（标准）
  #   16 GB GPU → 128 或 256
  # 每翻倍大约占用 4× 内存（STGCN 时序循环的中间激活）。
  hidden_channels: 128
  
  # 编码器层数（ST-GCN 堆叠深度）
  # 建议：4。增加至 6 对小数据集（<100 样本）通常过拟合。
  num_encoder_layers: 4
  
  # 解码器层数（时序卷积深度）
  # 建议：3。用于信号重建，比编码器浅足矣。
  num_decoder_layers: 3
  
  # 是否启用潜空间预测头
  # true：编码器潜向量的前 2/3 → 预测后 1/3，给预测头真正的梯度信号。
  use_prediction: true
  
  # 预测步数（T_future = T × 1/3 与此参数的最小值）
  # 建议：10（fMRI 10 TRs = 20s，EEG 10 pts = 40ms）。
  prediction_steps: 10
  
  # Dropout 比率
  # 建议：0.1。小数据集可提高到 0.2–0.3 以增强正则化。
  dropout: 0.1
  
  # 损失函数类型
  # mse: 均方误差，对离群值敏感。
  # huber: 对大误差用 L1，小误差用 MSE（推荐，对 EEG 高振幅尖峰鲁棒）。
  # smooth_l1: 与 huber 类似（delta=1）。
  loss_type: "huber"

  # 自迭代图结构学习（动态功能连接，Graph Structure Learning）
  # ─────────────────────────────────────────────────────────────
  # false（默认）：图拓扑固定为预处理时估计的相关矩阵（后向兼容）。
  # true：每个 ST-GCN 编码层内，从当前节点特征动态推算软邻接矩阵
  #       （余弦相似度 + top-k 稀疏化），与固定拓扑按可学习权重 α 混合。
  #
  # 科学依据：功能连接是动态的（Hutchison et al. 2013, NeuroImage），
  #           图结构应随认知状态实时重构，而非静态固定。
  # ML 参考：AGCRN (Bai et al. 2020), StemGNN (Cao et al. 2020)。
  #
  # 代价：每层多一次 [N, H//2] 矩阵乘法 (N≈200, H//2≈64 → 约 0.05ms)。
  # 建议：研究场景开启（true）；计算资源紧张时关闭（false）。
  use_dynamic_graph: false
  k_dynamic_neighbors: 10  # 动态图每节点保留的 k 近邻数（建议：fMRI 10，EEG 5）

# ──────────────────────────────────────────────────────────────────────────
# 三、训练配置
# ──────────────────────────────────────────────────────────────────────────
training:
  # 训练轮数
  # 建议：50–100（小数据集）；200（大数据集或启用 dFC 窗口后）。
  num_epochs: 100
  
  # 批次大小（当前实现每步一个图）
  batch_size: 1
  
  # 初始学习率
  # 建议：1e-4（Adam 系列的经典起点）。
  # 若 loss 在前 10 epoch 不下降，尝试 5e-4；若震荡，尝试 5e-5。
  learning_rate: 0.0001
  
  # 权重衰减（L2 正则化）
  # 建议：1e-5。小数据集可提高到 1e-4。
  weight_decay: 0.00001
  
  # 启用自适应损失平衡（GradNorm 变体）
  # true：自动平衡 recon_eeg/recon_fmri/pred_eeg/pred_fmri 的训练速度。
  use_adaptive_loss: true
  
  # 启用 EEG 通道增强（解决静默通道问题）
  use_eeg_enhancement: true
  
  # 启用梯度检查点（节省显存，对长序列必要）
  # 以重新计算换显存：ST-GCN 时序循环每步释放中间激活，防止 CUDA OOM。
  # 代价：约 20–30% 训练速度下降。
  use_gradient_checkpointing: true

  # 最大序列长度（单样本模式，windowed_sampling.enabled: false）
  # ─────────────────────────────────────────────────────────────
  # 截断到此长度再构建图，防止 CUDA OOM。
  # 建议：300（8 GB GPU）；600（16 GB GPU）。
  # 启用 windowed_sampling 后此参数无效（建议设为 null）。
  max_seq_len: 300
  
  # 启用学习率调度器（10–20% 更快收敛）
  use_scheduler: true
  # 调度器类型：cosine（推荐）/ onecycle / plateau
  # cosine：先线性预热，再余弦退火重启——对神经影像小数据集最稳定。
  scheduler_type: "cosine"
  
  # 梯度裁剪阈值（防止梯度爆炸）
  # 建议：1.0（Adam 系列标准）。
  max_grad_norm: 1.0
  
  # 梯度累积步数（等效增大批次大小，不增加内存）
  # ─────────────────────────────────────────────────────────────────────────
  # 默认 1 = 标准单步更新（后向兼容）。
  # 设为 N 时，每 N 步才执行一次 optimizer.step()，等效 batch_size = N × 1 = N。
  # loss 自动除以 N，梯度期望不变，幅度与单步一致。
  #
  # 科学依据：更大的等效 batch_size 减少梯度估计方差（Goodfellow et al. 2016 Ch.8）。
  # 对 N<100 样本的神经影像数据集，推荐 gradient_accumulation_steps=4（等效 batch=4）。
  # 建议：4（小数据集）；2（中等数据集）；1（大数据集）。
  gradient_accumulation_steps: 1  # 建议小数据集设为 4

  # 随机权重平均（Stochastic Weight Averaging, SWA）
  # ─────────────────────────────────────────────────────────────────────────
  # SWA 在主训练循环结束后，以固定低学习率继续训练若干 epoch，并对途中权重快照取平均。
  # 通过平均找到比单一 SGD 终点更宽/更平坦的极小值，提升 OOD 泛化 3-8%（Izmailov 2018）。
  #
  # 对神经影像场景特别有价值：测试被试的脑信号分布可能与训练集存在偏差，
  # 更宽的极小值对此类分布偏移更鲁棒。
  #
  # 参考：Izmailov et al. (2018) "Averaging Weights Leads to Wider Optima and
  #       Better Generalization" UAI 2018.
  #
  # false（默认）：不使用 SWA（后向兼容）。
  # true：主训练结束后额外运行 swa_epochs 轮 SWA 训练，结果保存为 swa_model.pt。
  use_swa: false
  # SWA 训练额外轮数（建议：总 epoch 数的 10-20%，例如 100 epoch 训练后 10-20 轮 SWA）
  swa_epochs: 10
  # SWA 学习率 = 初始 LR × swa_lr_ratio（建议：0.01–0.05；太小无法采集多样快照）
  swa_lr_ratio: 0.05
  
  # 验证频率（每 N 个 epoch 做一次验证）
  val_frequency: 5
  
  # 检查点保存频率（每 N 个 epoch 保存一次）
  save_frequency: 10
  
  # 早停耐心（连续 N 次验证无改善则停止）
  # 建议：20（允许 LR 重启后的短暂退步）。
  early_stopping_patience: 20

  # 时序数据增强（可选）
  # ─────────────────────────────────────────────────────────────────────────
  # 仅在训练阶段应用（model.training=True）；验证/推理时不增强，保证评估一致性。
  # 类型：信号级随机扰动，模拟采集噪声和个体幅度差异，提升泛化性。
  #
  # 科学依据：
  #   神经影像信号本身包含 10-20% 的测量噪声（仪器噪声、呼吸/心跳伪迹）。
  #   噪声注入（noise_std ≤ 0.05）和幅度缩放（scale_range ≤ ±10%）在有效
  #   信号范围内，不会破坏时序相关结构，等效于数据驱动的白噪声鲁棒性测试。
  #   参考：Perez et al. (2017) EEG 数据增强综述；Volpp et al. (2018) 时序增强。
  #
  # false（默认）：不增强（与旧版本行为完全一致）。
  # enabled: true 时，noise_std 和 scale_range 均生效；可分别设为 0 / null 禁用。
  augmentation:
    enabled: false
    # 高斯噪声标准差（z-scored 信号下，0.01 ≈ 1% 信号幅度）
    # 建议：0.01（轻度）~ 0.05（较强，适用于低 SNR 数据）
    noise_std: 0.01
    # 随机幅度缩放范围 [min, max]（相对于原始幅度）
    # 建议：[0.9, 1.1]（±10%），或 null 禁用幅度缩放
    scale_range: [0.9, 1.1]

# ── 时间窗口采样（动态功能连接 dFC 范式）────────────────────────────
# 将每条完整扫描（run）切分为多个重叠时间窗口。
#
# 科学依据（Hutchison 2013; Chang & Glover 2010）：
#   • 图拓扑（edge_index）= 完整 run 的相关性 → 稳定的结构连通性
#   • 节点特征（x）= 窗口切片 → 每窗口 = 一个脑状态快照 = 一个训练样本
#   • 多窗口 × 多被试 × 多任务 = 充足训练数据（n_subjects×n_tasks×n_windows）
#
# 与朴素截断（max_seq_len）的关键区别：
#   截断 → 丢弃数据，1 样本/run，EEG 连通性估计仅 1.2s（统计不可靠）
#   窗口 → 利用全部数据，N 样本/run，连通性来自完整 run（稳定可靠）
#
# 推荐配置（启用时将 max_seq_len 设为 null）：
#   fmri_window_size: 50   → 50 TRs × TR=2s = 100s ≈ 一个静息脑状态周期
#   eeg_window_size: 500   → 500pts ÷ 250Hz = 2s（覆盖 alpha/beta/gamma 节律）
#   stride_fraction: 0.5   → 50% 重叠 → 约 2× 更多样本（标准 dFC 设置）
windowed_sampling:
  enabled: false          # true = dFC 窗口模式（推荐研究使用）
                          # false = 单样本模式（与旧版本行为相同）
  fmri_window_size: 50    # fMRI 每个窗口的 TR 数（建议 30-100）
  eeg_window_size: 500    # EEG 每个窗口的采样点数（建议 250-2000）
  stride_fraction: 0.5    # 步长 = window_size × stride_fraction（0.5 = 50% 重叠）

  # 跨模态时间对齐（实验性功能）
  # false（默认）：各模态使用各自自然时间尺度（intra-modal 预测推荐）
  # true：EEG 窗口大小 = round(fmri_window_size × T_eeg / T_fmri)，
  #        强制 EEG/fMRI 窗口覆盖相同实际时长（跨模态预测时需要）
  #        ⚠ 启用前确认 GPU 内存足够：对齐后 EEG 窗口通常达数千点
  cross_modal_align: false

# ──────────────────────────────────────────────────────────────────────────
# 四、V5 精细优化（高级用户）
# 大多数用户无需修改这一节；系统会使用科学文献验证的默认值。
# ──────────────────────────────────────────────────────────────────────────
v5_optimization:
  # 学习率线性预热 epoch 数（cosine 调度器的第一阶段）
  # 预热期使用 10% → 100% 的线性 LR 斜坡，避免刚初始化时梯度爆炸。
  # 建议：5（约总 epoch 数的 5–10%）。
  warmup_epochs: 5

  # 自适应损失平衡（GradNorm 变体）
  adaptive_loss:
    # GradNorm 恢复力系数。较大 → 更激进地平衡各任务训练速度。
    # 建议：1.5（Chen et al. 2018 推荐值）。
    alpha: 1.5
    # 损失权重内部学习率
    # 建议：0.025（远小于主学习率，确保权重缓慢调整）。
    learning_rate: 0.025
    # 每隔多少步更新一次权重（频繁更新会引入噪声）
    update_frequency: 10
    # 预热 epoch 数（预热期权重固定为初始值，保证模型先有稳定梯度）
    warmup_epochs: 5
    # EEG/fMRI 信号能量比（用于初始化权重）
    # 注意：EEG 在 map_eeg_to_graph() 中已逐通道 z-score 归一化，与 fMRI 尺度相同；
    # 因此设为 1:1 即可。若使用未归一化的 EEG 数据，可调低 eeg 值（如 0.02）。
    modality_energy_ratios:
      eeg: 1.0
      fmri: 1.0
  
  # EEG 通道增强（解决"静默通道"导致的训练退化）
  eeg_enhancement:
    enable_monitoring: true   # 实时监控通道活动（SNR、方差、梯度）
    enable_dropout: true      # 对低活跃通道施加更高 dropout 概率
    enable_attention: true    # 可学习的通道重要性权重
    enable_regularization: true  # 熵+多样性+活动正则化，防止零解崩塌
    # 基础 dropout 比率（自适应 dropout 会在此基础上调整）
    # 建议：0.1–0.2（EEG 静默通道比例较高时可提高）。
    dropout_rate: 0.1
    # 通道注意力隐层维度（过大会过拟合，过小无法区分通道差异）
    attention_hidden_dim: 64
    # 熵正则化权重（鼓励输出分布多样，防止全零预测）
    entropy_weight: 0.01
    # 通道间多样性权重（防止所有通道输出相同波形）
    diversity_weight: 0.01
    # 活动强制权重（惩罚长期静默通道）
    activity_weight: 0.01
  
  # 潜空间预测头配置（EnhancedMultiStepPredictor）
  advanced_prediction:
    # 预测上下文长度（context_length）
    # ─────────────────────────────────────────────────────────────
    # 用于预测的历史时间步数 = 预测头的输入窗口大小。
    # 训练和推理使用完全相同的长度（因果对齐，无数据泄漏）。
    #
    # 科学依据（NPI 范式，NUST 等）：
    #   NPI 方法使用 3 或 70 个时间步的历史预测下一个时间步。
    #   本模型同样支持此范式；通过调节以下两个参数：
    #     context_length=70, prediction_steps=1  → "70步预测1步"（NPI风格）
    #     context_length=200, prediction_steps=10 → "200步预测10步"（长程预测）
    #
    # 默认值 200：
    #   对应 max_seq_len=300 时上下文部分的全部历史（2/3 × 300 = 200 步）。
    #   改为更小的值（如 70）可以用更少历史做预测，训练更稳定但长程信息减少。
    #
    # fMRI (TR=2s, 200步 × 2s = 400秒历史):  建议 context_length=50-200
    # EEG (250Hz, 200步 / 250Hz = 0.8秒历史): 建议 context_length=50-500
    context_length: 200
    # true：多尺度层级预测（粗→细，Transformer + 上采样）
    # 理论基础：大脑对时间信息的处理本身是层级的（Hasson et al. 2015）。
    use_hierarchical: true
    # true：使用 Transformer（长程依赖）；false：使用 GRU（短程、更快）
    # 建议：序列长度 < 100 用 GRU（内存低），> 100 用 Transformer。
    use_transformer: true
    # 不确定性估计头（预留接口，当前版本为后处理工具，不参与训练损失）
    # ─────────────────────────────────────────────────────────────
    # true：在预测头内注册一个 uncertainty_head（Linear → GELU → Linear），
    #       可通过 predictor.predictor(context, return_uncertainty=True) 手动获取
    #       对预测均值的对数方差估计（解释为置信区间大小的代理指标）。
    #
    # ⚠ 当前限制：uncertainty_head 不参与训练损失计算（NLL 损失**未**启用）。
    #   predict_next() 始终以 return_uncertainty=False 调用，
    #   因此 uncertainty_head 参数在训练中不接收梯度，其输出不保证有意义。
    #   若需可靠的不确定性估计，应在完成充分训练后：
    #   1. 手动调用: predictor.predictor(h_ctx, future_steps, return_uncertainty=True)
    #   2. 解读输出 log_var 作为定性置信度参考（非定量校准）
    #
    # false（建议，默认）：不注册 uncertainty_head，节省 ~input_dim×1.5 个参数。
    # 对大多数用户建议保持 false 直到明确需要不确定性量化。
    use_uncertainty: false
    # 时间尺度数（Hierarchical 模式下的粗-中-细层数）
    # 建议：3（2^2, 2^1, 2^0 下采样因子，覆盖不同频率成分）。
    num_scales: 3
    # 采样窗口数（每次 forward 从序列中采样的窗口数量，仅用于预训练/自监督）
    # 建议：3（Stratified 采样覆盖序列首/中/尾）。
    num_windows: 3
    # 窗口采样策略：uniform（均匀）/ random（随机）/ adaptive（重要性加权）
    sampling_strategy: "uniform"
    # 系统级预测传播层数（GraphPredictionPropagator）
    # 含义：预测在图上传播的跳数；2 = 覆盖 2-hop 邻居（A→B→C）
    # 建议：2（小图 N<100）；3（大图 N>200，如 Schaefer400）
    num_prop_layers: 2

# ──────────────────────────────────────────────────────────────────────────
# 五、图构建配置
# ──────────────────────────────────────────────────────────────────────────
graph:
  # fMRI 连通性阈值（Pearson |r| 超过此值才建边）
  # 建议：0.3（Bullmore & Sporns 2009 推荐，保留强连接）。
  # 降低 → 更密集图（内存增加）；提高 → 更稀疏图（可能丢失弱连接信息）。
  threshold_fmri: 0.3
  
  # EEG 连通性阈值
  # 建议：0.2（EEG 整体相关性较 fMRI 低，阈值稍低保留足够连接）。
  threshold_eeg: 0.2
  
  # fMRI K 近邻（每个节点保留最强的 K 条边，确保图连通性）
  # 建议：20（对 200 节点图平均度 ≈ 40，与实证小世界网络吻合）。
  k_nearest_fmri: 20
  
  # EEG K 近邻（EEG 节点数少，邻域更局部）
  # 建议：10（对 64 通道图平均度 ≈ 20）。
  k_nearest_eeg: 10
  
  # 是否添加自环（GNN 消息传递保留自身特征）
  add_self_loops: true
  
  # 是否无向图（脑连接通常双向对称）
  make_undirected: true
  
  # 跨模态距离阈值（mm，用于基于电极坐标的 EEG→fMRI 边建立）
  # 仅当 EEG 电极已通过 MNE 配准到 MNI 坐标系时有效；
  # 否则使用随机连接（connection_ratio）。
  cross_modal_distance_threshold: 30.0

  # EEG 通道间连通性计算方法
  # ─────────────────────────────────────────────────────────────────────────
  # "correlation"（默认）：Pearson 相关系数（时域，快速，后向兼容）。
  # "coherence"：宽带幅度相干性（频域，捕捉 alpha/beta/gamma 神经振荡同步）。
  #
  # 科学依据：相干性（coherence）衡量频域线性耦合，对振荡性神经活动更敏感：
  #   • Alpha (8-12 Hz)：视觉皮层放松态，枕-顶同步
  #   • Beta (13-30 Hz)：运动准备，感觉运动环路同步
  #   • Gamma (30-80 Hz)：认知绑定，局部回路
  # 若数据主要体现神经振荡特征，"coherence" 通常比 "correlation" 产生更有意义的图拓扑。
  #
  # 注意：修改此选项会改变 EEG 图的 edge_index 和 edge_attr；
  #       缓存键自动包含此参数，切换后旧缓存文件自动失效并重建。
  eeg_connectivity_method: "correlation"  # "correlation" 或 "coherence"

  # 跨模态边 Top-k：相关性最高的 fMRI ROI 数量（每个 EEG 电极）
  # ─────────────────────────────────────────────────────────────────────────
  # 默认行为（相关性可计算时）：对每个 EEG 通道保留与 fMRI BOLD 信号
  # 时序相关性最高的 k 个 ROI 作为跨模态邻居，边权重 = |Pearson r|。
  # 神经科学依据：神经血管耦合（Logothetis 2001）使 EEG 高频功率与
  # 局部 BOLD 信号呈线性相关 — 相关性边权让模型优先处理真实 NVC 通路。
  #
  # 建议：5（稀疏，与 k_nearest_eeg=10 的同模态图密度相当）。
  # 增大 → 跨模态连接更密，更多 EEG-fMRI 偶联信息，但可能增加噪声。
  # 降低 → 仅保留最强耦合通路，更保守但更可解释。
  # 注：跨模态边在每次加载缓存时动态重建，修改此值无需清空缓存。
  k_cross_modal: 5

# ──────────────────────────────────────────────────────────────────────────
# 六、输出配置
# ──────────────────────────────────────────────────────────────────────────
output:
  output_dir: "outputs"
  experiment_name: "twinbrain_v5"
  save_graphs: true
  save_predictions: true
  log_level: "INFO"

# ──────────────────────────────────────────────────────────────────────────
# 七、设备配置
# ──────────────────────────────────────────────────────────────────────────
device:
  # 设备类型："cuda"（GPU）/ "cpu"（CPU）/ "cuda:0"（指定 GPU）
  type: "cuda"
  
  # GPU 内存规格（仅用于日志提示，不影响实际分配）
  gpu_memory: "8GB"
  
  # 混合精度训练（AMP）——约 2× 速度提升，无精度损失
  # 建议：true（支持 CUDA 的 GPU 均推荐启用）。
  use_amp: True
  
  # torch.compile()（PyTorch 2.0+，约 20–40% 加速）
  # ⚠ 需要 Triton，Windows 不支持。Linux/macOS 且确认 `import triton` 成功后再开启。
  use_torch_compile: False
  compile_mode: "reduce-overhead"  # Options: default, reduce-overhead, max-autotune
